{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is for checking hallucination in out-domain using pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/home/s3886026/NLP_thesis/JoeyNMT/out-domain/JRC/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/s3886026/NLP_thesis/JoeyNMT/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set your source and target languages. Keep in mind, these traditionally use language codes as found here:\n",
    "# These will also become the suffix's of all vocab and corpus files used throughout\n",
    "source_language = \"de\"\n",
    "target_language = \"en\" \n",
    "lc = False  # If True, lowercase the data.\n",
    "seed = 42  # Random seed for shuffling.\n",
    "tag = \"baseline\" # Give a unique name to your folder - this is to ensure you don't rewrite any models you've already submitted\n",
    "\n",
    "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
    "os.environ[\"tgt\"] = target_language\n",
    "os.environ[\"tag\"] = tag\n",
    "\n",
    "# This will save it to a folder in our gdrive instead!\n",
    "!mkdir -p \"./$src-$tgt-$tag\"\n",
    "os.environ[\"env_path\"] = \"./%s-%s-%s\" % (source_language, target_language, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 ./out-domain/JRC/test.de\n",
      "1999 ./out-domain/JRC/test.en\n"
     ]
    }
   ],
   "source": [
    "# specify the file paths here\n",
    "source_file = \"./out-domain/JRC/test.de\"\n",
    "target_file = \"./out-domain/JRC/test.en\"\n",
    "\n",
    "\n",
    "# They should both have the same length.\n",
    "! wc -l \"$source_file\"\n",
    "! wc -l \"$target_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ./out-domain/JRC/test.de <==\r\n",
      "zusatzabkommen zum abkommen zwischen der europäischen wirtschaftsgemeinschaft sowie deren mitgliedstaaten und der schweizerischen eidgenossenschaft über uhrmacherwaren\r\n",
      "der rat der europäischen gemeinschaften\r\n",
      "einerseits\r\n",
      "der schweizerische bundesrat\r\n",
      "andererseits\r\n",
      "\r\n",
      "==> ./out-domain/JRC/test.en <==\r\n",
      "additional agreement to the agreement concerning products of the clock and watch industry between the european economic community and its member states and the swiss confederation\r\n",
      "the council of the european communities\r\n",
      "of the one part and\r\n",
      "the swiss federal council\r\n",
      "of the other part\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 \"$source_file\" \"$target_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses\n",
      "Requirement already satisfied: joblib in /apps/skylake/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from sacremoses) (0.13.2)\n",
      "Requirement already satisfied: click in /apps/skylake/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from sacremoses) (7.0)\n",
      "Requirement already satisfied: six in /apps/skylake/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from sacremoses) (1.12.0)\n",
      "Collecting regex (from sacremoses)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/6f/6daaa417aac2b3ec27b88411c3721b854a11a05f92164841a7bb3be48501/regex-2022.6.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Collecting tqdm (from sacremoses)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/c4/d15f1e627fff25443ded77ea70a7b5532d6371498f9285d44d62587e209c/tqdm-4.64.0-py2.py3-none-any.whl\n",
      "Installing collected packages: regex, tqdm, sacremoses\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/software/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages/regex'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is need for tokenization, thise can be done via sacremoses\n",
    "tok_source_file = source_file+\".tok\"\n",
    "tok_target_file = target_file+\".tok\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: sacremoses: command not found\n",
      "/bin/sh: sacremoses: command not found\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the source\n",
    "!sacremoses -l \"$source_language\" tokenize < \"$source_file\" > \"$tok_source_file\"\n",
    "# Tokenize the target\n",
    "!sacremoses -l \"$target_language\" tokenize < \"$target_file\" > \"$tok_target_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look what tokenization did to the text.\n",
    "! head \"$source_file\"*\n",
    "! head \"$target_file\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the pointers to our files such that we continue to work with the tokenized data.\n",
    "source_file = tok_source_file\n",
    "target_file = tok_target_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /home/s3886026/NLP_thesis/JoeyNMT/out-domain/JRC/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#path to the encoded files used for training\n",
    "#os.environ[\"dataset\"]=\"./de-en-baseline/data\"\n",
    "os.environ[\"law_out\"]= \"/home/s3886026/NLP_thesis/JoeyNMT/out-domain/JRC/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-bdfca8fbe636>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-bdfca8fbe636>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    import subword-nmt\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "# os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
    "# os.environ[\"tgt\"] = target_language\n",
    "\n",
    "# Learn BPEs on the training data.\n",
    "#os.environ[\"law_out\"] = path.join(\"joeynmt\", \"data2\", source_language + target_language) # Herman! \n",
    "! subword-nmt learn-joint-bpe-and-vocab --input data/test.de data/test.en -s 2000 \\\n",
    "                                -o data/bpe.codes.2000 --write-vocabulary data/vocab.de data/vocab.en\n",
    "\n",
    "# Apply BPE splits to the development and test data.\n",
    "# ! subword-nmt apply-bpe -c $dataset/bpe.codes.32000 --vocabulary $dataset/vocab.$src --dropout 0.1 --seed 42 < $dataset/train.$src > $dataset/train.bpe.$src\n",
    "# ! subword-nmt apply-bpe -c $dataset/bpe.codes.32000 --vocabulary $dataset/vocab.$tgt --dropout 0.1 --seed 42 < $dataset/train.$tgt > $dataset/train.bpe.$tgt\n",
    "\n",
    "! subword-nmt apply-bpe -c data/bpe.codes.2000 --vocabulary data/vocab.de < data/test.de > data/test.bpe.de\n",
    "! subword-nmt apply-bpe -c data/bpe.codes.2000 --vocabulary data/vocab.en < data/test.de > data/test.bpe.en"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jnmt_env",
   "language": "python",
   "name": "jnmt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
